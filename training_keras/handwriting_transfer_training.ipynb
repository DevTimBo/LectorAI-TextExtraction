{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2076a59",
   "metadata": {},
   "source": [
    "# Author: Tim Harmling and Alexej Kravtschenko\n",
    "- **Note:** This notebook was written by the combined effort of Tim Harmling and Alexej Kravtschenko \n",
    "- **Description:** Automatic Workflow to Transfer Learn the Handwriting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617741a46be8f4e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:35.194604Z",
     "start_time": "2024-02-15T16:00:30.093631800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import handwriting.load_data as load_data\n",
    "import load_transfer_data\n",
    "import models as models # Use: build_model9v3(img_width, img_height, char) \n",
    "#Imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pickle\n",
    "import time\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d912de093664402a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cafc2f961d6b8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:35.210719Z",
     "start_time": "2024-02-15T16:00:35.200081Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50ebf19d620853",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96e3bacfefa84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:35.285387300Z",
     "start_time": "2024-02-15T16:00:35.212227900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_img_paths, y_train_labels = load_transfer_data.get_train_data()\n",
    "x_val_img_paths, y_val_labels = load_transfer_data.get_validation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc94188289acd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:35.314372500Z",
     "start_time": "2024-02-15T16:00:35.287382500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(f\"Training path: {x_train_img_paths[0:2]}\", y_train_labels[0:2])\n",
    "print(f\"Validation path: {x_val_img_paths[0:2]}\", y_val_labels[0:2])\n",
    "#print(f\"Testing path: {x_test_img_paths[0:2]}\", y_test_labels[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d396ce20431c83",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c72e5da9634ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:36.149966700Z",
     "start_time": "2024-02-15T16:00:35.306394300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Has to be here because load data functions need to be called before\n",
    "import tokenizer as tokenizer\n",
    "\n",
    "# train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels, (IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "train_ds = tokenizer.prepare_augmented_dataset(x_train_img_paths, y_train_labels, BATCH_SIZE)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267aa06119792c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Show Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1843d431baf541",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:37.151314100Z",
     "start_time": "2024-02-15T16:00:36.154953400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data in train_ds.take(1):\n",
    "    images, labels = data[\"image\"], data[\"label\"]\n",
    "\n",
    "    ax = plt.subplots(4, 4, figsize=(32, 8))[1]\n",
    "\n",
    "    for i in range(BATCH_SIZE):\n",
    "        img = images[i]\n",
    "        img = tf.image.flip_left_right(img)\n",
    "        img = tf.transpose(img, perm=[1, 0, 2])\n",
    "        img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "        img = img[:, :, 0]\n",
    "\n",
    "        # Gather indices where label!= padding_token.\n",
    "        label = labels[i]\n",
    "        indices = tf.gather(label, tf.where(tf.math.not_equal(label, tokenizer.padding_token)))\n",
    "        # Convert to string.\n",
    "        label = tf.strings.reduce_join(tokenizer.num_to_char(indices))\n",
    "        label = label.numpy().decode(\"utf-8\")\n",
    "\n",
    "        ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "        ax[i // 4, i % 4].set_title(label)\n",
    "        ax[i // 4, i % 4].axis(\"off\")\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de342f6f643d2f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9c9f0a326f83ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:37.413702700Z",
     "start_time": "2024-02-15T16:00:37.171441600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights_keras_string =\"_weights.keras\"\n",
    "\n",
    "def model_load_weights_if_exists(model):\n",
    "    \"\"\"Loads model weights if they exist.\n",
    "\n",
    "    This function checks if the model weights exist and loads them into the model.\n",
    "\n",
    "    Args:\n",
    "        model: The Keras model.\n",
    "\n",
    "    Returns: \n",
    "        None\n",
    "    \"\"\"\n",
    "    MODEL_MODEL_PATH = MODEL_NAME\n",
    "    MODEL_WEIGHT_PATH = MODEL_NAME + weights_keras_string\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, MODEL_MODEL_PATH)\n",
    "    model_weight_path = os.path.join(model_path, MODEL_WEIGHT_PATH)\n",
    "    print(model_path)\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Resuming Training where we left off!\")\n",
    "        model.load_weights(model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678df9fcdf15f347",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:37.415697200Z",
     "start_time": "2024-02-15T16:00:37.185455300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    \"\"\"Trains the model and returns prediction model and training history.\n",
    "\n",
    "    This function trains the provided model using the training and validation datasets.\n",
    "    It also returns a prediction model and training history.\n",
    "\n",
    "    Args:\n",
    "        model: The Keras model to be trained.\n",
    "\n",
    "    Returns:\n",
    "        prediction_model: The model used for predictions.\n",
    "        history: The training history.\n",
    "    \"\"\"\n",
    "    #model_load_weights_if_exists(model)\n",
    "        \n",
    "    prediction_model = keras.models.Model(model.get_layer(name=\"image\").input, model.get_layer(name=\"dense2\").output)\n",
    "    early_stopping = EarlyStopping(patience=PATIENCE, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=PATIENCE, min_lr=1e-9, verbose=2) \n",
    "    \n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[reduce_lr, early_stopping])  \n",
    "     \n",
    "    return prediction_model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce72291f",
   "metadata": {},
   "source": [
    "# Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccc731e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:37.447358900Z",
     "start_time": "2024-02-15T16:00:37.201964300Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model_and_weights():\n",
    "    \"\"\"Loads a pre-trained model and its weights.\n",
    "\n",
    "    This function, loads a pre-trained model and its weights\n",
    "    from the specified directory. It checks if both the model and weights exist before loading.\n",
    "\n",
    "    Returns:\n",
    "        model: The pre-trained Keras model with loaded weights, if found. Default: model9v3_xl\n",
    "    \"\"\"\n",
    "    weights_keras_string = \"_weights.keras\"\n",
    "    MODEL_MODEL_PATH = MODEL_NAME\n",
    "    MODEL_WEIGHT_PATH = MODEL_NAME + weights_keras_string\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, MODEL_MODEL_PATH)\n",
    "    model_weight_path = os.path.join(model_path, MODEL_WEIGHT_PATH)\n",
    "    model_weight_path = \"models\\old_goat\\old_goat_weights.keras\"\n",
    "    model_path = \"models\\old_goat\"\n",
    "    print(model_path)\n",
    "    if os.path.exists(model_path):\n",
    "        print(\"Loading pre-trained model and weights...\")\n",
    "        model = load_model(model_path)\n",
    "        model.load_weights(model_weight_path)\n",
    "        print(\"Model and weights loaded successfully.\")\n",
    "\n",
    "        return model\n",
    "    else:\n",
    "        print(\"No pre-trained model or weights found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02884dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:00:46.284329600Z",
     "start_time": "2024-02-15T16:00:37.213944900Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model_and_weights()\n",
    "max_len = len(tokenizer.char_to_num.get_vocabulary())\n",
    "characters = tokenizer.char_to_num.get_vocabulary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42889b3f227d93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:01:06.601139900Z",
     "start_time": "2024-02-15T16:01:06.380814600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_ds = tokenizer.prepare_dataset(x_train_img_paths, y_train_labels, (IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)\n",
    "#train_ds = tokenizer.prepare_augmented_dataset(x_train_img_paths, y_train_labels, BATCH_SIZE)\n",
    "# val_ds = tokenizer.prepare_dataset(x_val_img_paths, y_val_labels,(IMAGE_WIDTH,IMAGE_HEIGHT),BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9529b2",
   "metadata": {},
   "source": [
    "### Dense Layer Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdbe79b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:03:59.705783300Z",
     "start_time": "2024-02-15T16:01:09.566868300Z"
    }
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prediction_model, history = train_model(model)\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"Gesamte Trainingsdauer: {time}s\".format(time=round(total_duration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "prediction_model, history = train_model(model)\n",
    "\n",
    "total_duration = time.time() - start_time\n",
    "print(\"Gesamte Trainingsdauer: {time}s\".format(time=round(total_duration)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc27d01fe397042",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "# Plot helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443bfc89b1a8fea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:10.973822100Z",
     "start_time": "2024-02-15T16:04:10.941150600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_history(history, name, dir_path, save_fig):\n",
    "    \"\"\"Plots the training history of a model.\n",
    "    \n",
    "    This function takes the training history of a model and plots the training and validation loss\n",
    "    across epochs. It also plots the learning rate on a secondary y-axis using a logarithmic scale.\n",
    "\n",
    "    Args:\n",
    "        history: The training history of the model.\n",
    "        name (str): The name of the model.\n",
    "        dir_path (str): The directory path to save the plot.\n",
    "        save_fig (bool): A flag indicating whether to save the plot as an image.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    metrics = history.history\n",
    "    _, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot für Trainings- und Validierungsverluste\n",
    "    ax1.plot(metrics['loss'], label='Training Loss', color='blue')\n",
    "    ax1.plot(metrics['val_loss'], label='Validation Loss', color='red')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss', color='black')\n",
    "    ax1.tick_params('y', colors='black')\n",
    "    ax1.legend(loc='upper left', bbox_to_anchor=(0.0, 0.95))  \n",
    "\n",
    "    # Zweite Y-Achse für die Lernrate\n",
    "    ax2 = ax1.twinx()\n",
    "    #ax2.plot(metrics['lr'], label='Learning Rate', color='green')\n",
    "    ax2.set_ylabel('Learning Rate', color='black')\n",
    "    \n",
    "    ax2.set_yscale('log')  # Verwende logarithmische Skala für die Lernrate\n",
    "    \n",
    "    ax2.tick_params('y', colors='black')\n",
    "    ax2.yaxis.set_major_formatter(StrMethodFormatter('{x:1.0e}'))\n",
    "    ax2.legend(loc='upper right', bbox_to_anchor=(1.0, 0.95))  \n",
    "    \n",
    "    if save_fig:\n",
    "        plt.title('Name: '+name)\n",
    "        path = os.path.join(dir_path, name + '_history.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d89800205cdc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:10.991434100Z",
     "start_time": "2024-02-15T16:04:10.977329700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creates a directory if it doesn't exist\n",
    "def create_dir(path_to_dir):\n",
    "    isExist = os.path.exists(path_to_dir)\n",
    "    if not isExist:\n",
    "        os.makedirs(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c285abdfcc81c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:11.012658600Z",
     "start_time": "2024-02-15T16:04:10.992457600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A utility function to decode the output of the network.\n",
    "def decode_batch_predictions(pred):\n",
    "    input_len = np.ones(pred.shape[0]) * pred.shape[1]\n",
    "    # Use greedy search. For complex tasks, you can use beam search.\n",
    "    results = keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0][:, :load_transfer_data.max_len]\n",
    "    # Iterate over the results and get back the text.\n",
    "    output_text = []\n",
    "    for res in results:\n",
    "        res = tf.gather(res, tf.where(tf.math.not_equal(res, -1)))\n",
    "        res = tf.strings.reduce_join(tokenizer.num_to_char(res)).numpy().decode(\"utf-8\")\n",
    "        output_text.append(res)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e2678f21bfbbb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:11.025763800Z",
     "start_time": "2024-02-15T16:04:11.008697500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_evaluation(name, dir_path, save_fig):\n",
    "    for batch in val_ds.take(1):\n",
    "        batch_images = batch[\"image\"]\n",
    "        _, ax = plt.subplots(4, 4, figsize=(32, 8))\n",
    "\n",
    "        preds = prediction_model.predict(batch_images)\n",
    "        pred_texts = decode_batch_predictions(preds)\n",
    "\n",
    "        for i in range(BATCH_SIZE):\n",
    "            img = batch_images[i]\n",
    "            img = tf.image.flip_left_right(img)\n",
    "            img = tf.transpose(img, perm=[1, 0, 2])\n",
    "            img = (img * 255.0).numpy().clip(0, 255).astype(np.uint8)\n",
    "            img = img[:, :, 0]\n",
    "\n",
    "            title = f\"Prediction: {pred_texts[i]}\"\n",
    "            ax[i // 4, i % 4].imshow(img, cmap=\"gray\")\n",
    "            ax[i // 4, i % 4].set_title(title)\n",
    "            ax[i // 4, i % 4].axis(\"off\")   \n",
    "    if save_fig:\n",
    "        path = os.path.join(dir_path, name + '_result.png')\n",
    "        plt.savefig(path)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fec561",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:11.048268700Z",
     "start_time": "2024-02-15T16:04:11.023654600Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_new_plot_name(model_name, names, format):\n",
    "    pattern = r\"\\d+\"\n",
    "    max_number = 0\n",
    "    for name in names:\n",
    "        tmp_name = name.replace(model_name,\"\")\n",
    "        number = int(re.findall(pattern,tmp_name)[0])\n",
    "        if number > max_number:\n",
    "            max_number = number\n",
    "            \n",
    "    new_model_name = model_name + \"V_\" + str(max_number + 1)\n",
    "    \n",
    "    return format.replace(model_name,new_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46158f62a4aac633",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958dca138b01f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:14.334693500Z",
     "start_time": "2024-02-15T16:04:11.043727100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" Creates a new plot name based on existing names.\n",
    "\n",
    "This function generates a new plot name by appending a version number to the given model name.\n",
    "The version number is determined based on existing plot names in the directory.\n",
    "\n",
    "Args:\n",
    "    model_name (str): The base model name.\n",
    "    names (list): A list of existing plot names.\n",
    "    format (str): The format string for the plot name.\n",
    "\n",
    "Returns:\n",
    "    str: The new plot name.\n",
    "\"\"\"\n",
    "if not os.path.exists(TEST_RESULT_DIR_NAME):\n",
    "            create_dir(TEST_RESULT_DIR_NAME)\n",
    "files_with_model_name = [file for file in os.listdir(TEST_RESULT_DIR_NAME) if MODEL_NAME in file]\n",
    "metrics = history.history\n",
    "\n",
    "NAME = \"{name}_{epoch}E_{height}H_{width}W_{loss}L_{val_loss}VL_{time}s\".format(\n",
    "    name=MODEL_NAME, epoch=history.epoch[-1], height=IMAGE_HEIGHT, width=IMAGE_WIDTH,\n",
    "    loss=round(metrics['loss'][-1],2), val_loss=round(metrics['val_loss'][-1], 2), time=round(total_duration))\n",
    "\n",
    "if not files_with_model_name:\n",
    "    if SAVE_HISTORY:\n",
    "        plot_history(history, NAME, TEST_RESULT_DIR_NAME, True)\n",
    "        plot_evaluation(NAME, TEST_RESULT_DIR_NAME, True)\n",
    "else:\n",
    "    new_name = create_new_plot_name(MODEL_NAME,files_with_model_name, NAME)\n",
    "    plot_history(history, new_name, TEST_RESULT_DIR_NAME, True)\n",
    "    plot_evaluation(new_name, TEST_RESULT_DIR_NAME, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ca800c",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde914d352e2192",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-15T16:04:30.836290100Z",
     "start_time": "2024-02-15T16:04:14.342181300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Saves the model after training if MODEL_SAVE = True\n",
    "if MODEL_SAVE:\n",
    "    if not os.path.exists(MODEL_DIR_NAME):\n",
    "        create_dir(MODEL_DIR_NAME)\n",
    "    model_path = os.path.join(MODEL_DIR_NAME, \"{model_name}\".format(model_name=MODEL_NAME))\n",
    "    model.save(model_path)\n",
    "    model.save_weights(os.path.join(model_path, f\"{MODEL_NAME}{weights_keras_string}\"), overwrite=True, save_format=None, options=None)\n",
    "    json_string = model.to_json()\n",
    "\n",
    "    with open(os.path.join(model_path, f\"{MODEL_NAME}.json\"),'w') as f:\n",
    "        f.write(json_string)\n",
    "\n",
    "    data_to_save = (load_transfer_data.max_len, load_transfer_data.characters)\n",
    "    import pickle\n",
    "    with open(os.path.join(model_path, \"handwriting_chars.pkl\"), 'wb') as file:\n",
    "        pickle.dump(data_to_save, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
