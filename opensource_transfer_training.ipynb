{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe864d5b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40281f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, default_data_collator\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from datasets import load_metric\n",
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32228c",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4eb795",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_source_model_name = \"microsoft/trocr-base-handwritten\"\n",
    "save_model_name = f\"models/{open_source_model_name.split('/')[-1]}-finetuned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444086ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset/dataset_training/'\n",
    "train_dataset_path = os.path.join(dataset_path, 'train')\n",
    "val_dataset_path = os.path.join(dataset_path, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef415e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632d040",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ce0323-d185-4e6f-b9ef-04c218f7c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_list = os.listdir(train_dataset_path)\n",
    "val_df_list = os.listdir(val_dataset_path)\n",
    "\n",
    "train_df_jpg_list = [train_df_list[i] for i in range(len(train_df_list)) if train_df_list[i].endswith('.jpg')]\n",
    "val_df_jpg_list = [val_df_list[i] for i in range(len(val_df_list)) if val_df_list[i].endswith('.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc504698",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(columns=['file_name', 'text'])\n",
    "val_df = pd.DataFrame(columns=['file_name', 'text'])\n",
    "\n",
    "for i in range(len(train_df_jpg_list)):\n",
    "    text_file = f\"{train_df_jpg_list[i].split('.')[0]}.txt\"\n",
    "    with open(os.path.join(dataset_path, 'train', text_file), 'r') as f:\n",
    "        text = f.read()\n",
    "    train_df.loc[i] = {'file_name': train_df_jpg_list[i], 'text': text}\n",
    "\n",
    "for i in range(len(val_df_jpg_list)):\n",
    "    text_file = f\"{val_df_jpg_list[i].split('.')[0]}.txt\"\n",
    "    with open(os.path.join(dataset_path, 'val', text_file), 'r') as f:\n",
    "        text = f.read()\n",
    "    val_df.loc[i] = {'file_name': val_df_jpg_list[i], 'text': text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0807c7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84351e98",
   "metadata": {},
   "source": [
    "### Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463236f-01e8-4c49-b5ff-5fee06f836f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['file_name'][idx]\n",
    "        text = str(self.df['text'][idx])  # Convert text to string explicitly\n",
    "        \n",
    "        # Prepare image (i.e. resize + normalize)\n",
    "        image_path = os.path.join(self.root_dir, file_name)  # Create full file path\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        # Add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, \n",
    "                                           padding=\"max_length\", \n",
    "                                           max_length=self.max_target_length).input_ids\n",
    "        \n",
    "        # Important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2a3e66",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf03fe-c8f0-4b05-9078-9cfdaf39ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(open_source_model_name)\n",
    "train_dataset = Dataset(root_dir=train_dataset_path,\n",
    "                           df=train_df,\n",
    "                           processor=processor)\n",
    "eval_dataset = Dataset(root_dir=val_dataset_path,\n",
    "                           df=val_df,\n",
    "                           processor=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c781ad02-a153-4171-8099-cc74fa70eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ea5799",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca4cbb6-7d4c-4a38-9997-7c6395a8b8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = train_dataset[0]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4742c3-0b07-4353-bdd0-1b5097295e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(os.path.join(train_dataset.root_dir , train_df['file_name'][0])).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cb5562-921d-4d8f-ac86-0dd8f379afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = encoding['labels']\n",
    "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b0ef74",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d05ce1-df74-451b-8e15-41c36db24708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(open_source_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a35b9a9-7c30-4f66-bd2e-83996012c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e076a5a-1084-4bae-b6bf-82ea816fd27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    num_train_epochs=2,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    fp16=False, \n",
    "    output_dir=\"./\",\n",
    "    logging_steps=2,\n",
    "    save_steps=200,\n",
    "    eval_steps=200,\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1341d9cc-052d-4371-b952-896508aaf00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cer_metric = load_metric(\"cer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f98ff8-4310-46e3-a018-73ab423f2fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022190b8-b1c5-4764-826e-6a20a55d29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    tokenizer=processor.image_processor,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    data_collator=default_data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(400)]\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebdbdf-2c40-4979-a8ec-fd9dea1ab209",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.evaluate(eval_dataset=eval_dataset)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246dc8b",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad68a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(save_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f70516",
   "metadata": {},
   "source": [
    "### Try Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba333ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = TrOCRProcessor.from_pretrained(open_source_model_name)\n",
    "model = VisionEncoderDecoderModel.from_pretrained(save_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94174df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted; True\")\n",
    "for i, eval in enumerate(eval_dataset):\n",
    "    pixel_values = eval['pixel_values'].unsqueeze(0)\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    real_text = val_df['text'][i]\n",
    "    print(generated_text, real_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf.gpusupenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
